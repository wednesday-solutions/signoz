version: "3.9"

services:
  clickhouse:
    image: clickhouse/clickhouse-server:22.4.5-alpine
    # ports:
    #   - "9000:9000"
    #   - "8123:8123"
    tty: true
    volumes:
      - ./clickhouse-config.xml:/etc/clickhouse-server/config.xml
      - ./clickhouse-users.xml:/etc/clickhouse-server/users.xml
      # - ./clickhouse-storage.xml:/etc/clickhouse-server/config.d/storage.xml
      - ./data/clickhouse/:/var/lib/clickhouse/
    deploy:
      restart_policy:
        condition: on-failure
    logging:
      options:
        max-size: 50m
        max-file: "3"
    healthcheck:
      # "clickhouse", "client", "-u ${CLICKHOUSE_USER}", "--password ${CLICKHOUSE_PASSWORD}", "-q 'SELECT 1'"
      test: ["CMD", "wget", "--spider", "-q", "localhost:8123/ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  alertmanager:
    image: signoz/alertmanager:0.23.0-0.1
    volumes:
      - ./data/alertmanager:/data
    command:
      - --queryService.url=http://query-service:8085
      - --storage.path=/data
    depends_on:
      - query-service
    deploy:
      restart_policy:
        condition: on-failure

  query-service:
    image: signoz/query-service:0.10.0
    command: ["-config=/root/config/prometheus.yml"]
    # ports:
    #   - "6060:6060"     # pprof port
    #   - "8080:8080"     # query-service port
    volumes:
      - ./prometheus.yml:/root/config/prometheus.yml
      - ../dashboards:/root/config/dashboards
      - ./data/signoz/:/var/lib/signoz/
    environment:
      - ClickHouseUrl=http://13.127.125.243:9000/?database=signoz_traces
      - STORAGE=clickhouse
      - GODEBUG=netdns=go
      - TELEMETRY_ENABLED=true
      - DEPLOYMENT_TYPE=docker-swarm

    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:8080/api/v1/version"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      restart_policy:
        condition: on-failure
    depends_on:
      - clickhouse

  frontend:
    image: signoz/frontend:0.10.0
    deploy:
      restart_policy:
        condition: on-failure
    depends_on:
      - alertmanager
      - query-service
    ports:
      - "3301:3301"
    volumes:
      - ../common/nginx-config.conf:/etc/nginx/conf.d/default.conf

  otel-collector:
    image: signoz/otelcontribcol:0.45.1-1.1
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      # - "1777:1777"     # pprof extension
      - "4317:4317"     # OTLP gRPC receiver
      - "4318:4318"     # OTLP HTTP receiver
      # - "8888:8888"     # OtelCollector internal metrics
      # - "8889:8889"     # signoz spanmetrics exposed by the agent
      # - "9411:9411"     # Zipkin port
      # - "13133:13133"   # Health check extension
      # - "14250:14250"   # Jaeger gRPC
      # - "14268:14268"   # Jaeger thrift HTTP
      # - "55678:55678"   # OpenCensus receiver
      # - "55679:55679"   # zPages extension
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name={{.Node.Hostname}},os.type={{.Node.Platform.OS}},dockerswarm.service.name={{.Service.Name}},dockerswarm.task.name={{.Task.Name}}
    deploy:
      mode: replicated
      replicas: 3
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2000m
    depends_on:
      - clickhouse

  otel-collector-metrics:
    image: signoz/otelcontribcol:0.45.1-1.1
    command: ["--config=/etc/otel-collector-metrics-config.yaml"]
    volumes:
      - ./otel-collector-metrics-config.yaml:/etc/otel-collector-metrics-config.yaml
    # ports:
    #   - "1777:1777"     # pprof extension
    #   - "8888:8888"     # OtelCollector internal metrics
    #   - "13133:13133"   # Health check extension
    #   - "55679:55679"   # zPages extension
    deploy:
      restart_policy:
        condition: on-failure
    depends_on:
      - clickhouse

  hotrod:
    image: jaegertracing/example-hotrod:1.30
    command: ["all"]
    environment:
      - JAEGER_ENDPOINT=http://otel-collector:14268/api/traces
    logging:
      options:
        max-size: 50m
        max-file: "3"

  load-hotrod:
    image: "grubykarol/locust:1.2.3-python3.9-alpine3.12"
    hostname: load-hotrod
    environment:
      ATTACKED_HOST: http://hotrod:8080
      LOCUST_MODE: standalone
      NO_PROXY: standalone
      TASK_DELAY_FROM: 5
      TASK_DELAY_TO: 30
      QUIET_MODE: "${QUIET_MODE:-false}"
      LOCUST_OPTS: "--headless -u 10 -r 1"
    volumes:
      - ../common/locust-scripts:/locust
